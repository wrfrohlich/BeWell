{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\" face=\"Times\"> <b>Create Categories File</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Variables</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_raw_data = \"D:/Unisinos/Bitalino/01 - Raw Data/All Data/\"\n",
    "read_annotations = \"D:/Unisinos/Bitalino/02 - Data Control/annotations.csv\"\n",
    "write_data = \"D:/Unisinos/Bitalino/03 - Data CSV/\"\n",
    "file_type = \"_file.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Libraries</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pytz\n",
    "import datetime\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from collections import Counter\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Read All the Files and Process the Data </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_pwd = read_raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201806130369 - 1564678273\n",
      "201806130369 - 1564678784\n",
      "201806130369 - 1573754008\n",
      "201806130369 - 1573754318\n",
      "201806130369 - 1573755364\n",
      "201806130369 - 1573757623\n",
      "201806130369 - 1573757727\n",
      "201806130369 - 1571157902\n",
      "201806130369 - 1571158125\n",
      "201806130369 - 1571159209\n",
      "201806130369 - 1571159603\n",
      "201806130369 - 1571159660\n",
      "201806130369 - 1561651609\n",
      "201806130369 - 1561651799\n",
      "201806130369 - 1561651880\n",
      "201806130369 - 1561652059\n",
      "201806130369 - 1561652432\n",
      "201806130369 - 1561652546\n",
      "201806130369 - 1561652596\n",
      "201806130369 - 1561653093\n",
      "201806130369 - 1561653144\n",
      "201806130369 - 1561653283\n",
      "201806130369 - 1561654308\n",
      "201806130369 - 1561654366\n",
      "201806130369 - 1561654439\n",
      "201806130369 - 1561654481\n",
      "201806130369 - 1561654554\n",
      "201806130369 - 1567097819\n",
      "201806130369 - 1567098307\n",
      "201806130369 - 1567098361\n",
      "201806130369 - 1567098679\n",
      "201806130369 - 1567099364\n"
     ]
    }
   ],
   "source": [
    "files = {}\n",
    "data = []\n",
    "for participant_folder in listdir(_pwd):\n",
    "    _participant = participant_folder.split(' ')[1]\n",
    "    for folder in listdir(_pwd + participant_folder):\n",
    "        print(folder)\n",
    "        data_timestamp = int(folder.split('-')[1].lstrip())\n",
    "        data_timestamp = datetime.datetime.fromtimestamp(data_timestamp)\n",
    "\n",
    "        files = [f for f in listdir(_pwd+participant_folder+'/'+folder) if isfile(join(_pwd+participant_folder+'/'+folder, f))]\n",
    "\n",
    "        for f in files:\n",
    "            file_index = int(f.split('.')[0])\n",
    "            data_values = pickle.load(open(_pwd+participant_folder+'/'+folder+'/'+f, \"rb\")).tolist()\n",
    "            data_values = pd.DataFrame(data_values)\n",
    "            data_values.columns = ['DIGITAL{0}'.format(x) for x in range(0,len(data_values.columns))]\n",
    "            data_values.rename(columns={'DIGITAL6':'ECG','DIGITAL7':'EMG','DIGITAL8':'EDA'}, inplace=True)\n",
    "            data_values['PARTICIPANT'] = _participant\n",
    "\n",
    "            data_values['ECG'] = [((((x/1024)-(1/2))*3.3)/1100)*1000 for x in data_values['ECG']]\n",
    "\n",
    "            data_values['FILEINDEX'] = file_index\n",
    "\n",
    "            # At each entry counts as a more one milesecond (@1000Hz)\n",
    "            row_objects = [1000]*len(data_values)\n",
    "            row_objects = list(np.cumsum(row_objects))\n",
    "            row_objects = [data_timestamp + datetime.timedelta(milliseconds=int(x)) for x in row_objects]\n",
    "\n",
    "            data.append(pd.concat([pd.DataFrame(row_objects, columns=['TIMESTAMP']), data_values], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Merge All Data into a Same Data Frame </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the TIMESTAMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TIMESTAMP'] = data['TIMESTAMP'].apply(lambda x: x.to_pydatetime().replace(tzinfo=pytz.timezone('America/Sao_Paulo')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values(['TIMESTAMP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete unused columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(['DIGITAL0','DIGITAL1','DIGITAL2','DIGITAL3','DIGITAL4','DIGITAL5','DIGITAL9','DIGITAL10','FILEINDEX'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Read the Annotations and Preprocess<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = pd.read_csv(read_annotations, sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace NaN with None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = annotations.where((pd.notnull(annotations)), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations['PARTICIPANTE'] = annotations['PARTICIPANTE'].apply(lambda x: x.lstrip().rstrip() if x is not None else x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method to Combine <b>Date</b> and <b>Time</b> into a <b>Datetime</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_date_time(xdate, xtime):\n",
    "    new_feature = []\n",
    "    for d,t in zip(xdate,xtime):\n",
    "        if d is None or t is None:\n",
    "            new_feature.append(None)\n",
    "        else:\n",
    "            new_feature.append(datetime.datetime.strptime(d + ' ' + t, '%d/%m/%Y %H:%M'))\n",
    "    return new_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_date_time(xdate, xtime):\n",
    "    new_feature = []\n",
    "    for d,t in zip(xdate,xtime):\n",
    "        if d is None or t is None:\n",
    "            new_feature.append(None)\n",
    "        else:\n",
    "            new_feature.append(datetime.datetime.strptime(t, '%d-%m-%Y %H:%M'))\n",
    "    return new_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cast <b>Start Time</b> and <b>End Time</b> into <b>Datetime</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations['HORAINICIO'] = combine_date_time(annotations['DATA'],annotations['HORAINICIO'])\n",
    "annotations['HORAFINAL'] = combine_date_time(annotations['DATA'],annotations['HORAFINAL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cast <b>timer</b> into <b>datetime.time</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations['CRONOMETROINICIO'] = annotations['CRONOMETROINICIO'].apply(lambda x: datetime.datetime.strptime(x, '%H:%M:%S').time() if isinstance(x, str) else None)\n",
    "annotations['CRONOMETROFINAL'] = annotations['CRONOMETROFINAL'].apply(lambda x: datetime.datetime.strptime(x, '%H:%M:%S').time() if isinstance(x, str) else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fulfill Missing <b>HORAFINAL</b> Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def get_next(some_iterable, window=1):\n",
    "    items, nexts = itertools.tee(some_iterable, 2)\n",
    "    nexts = itertools.islice(nexts, window, None)\n",
    "    return zip(items, nexts)\n",
    "\n",
    "new_feature = []\n",
    "\n",
    "for _current, _next in get_next(zip(annotations['PARTICIPANTE'], annotations['HORAINICIO'],annotations['HORAFINAL'])):\n",
    "    if _next[0] == _current[0]:\n",
    "        if (_current[1] is None) or (isinstance(_current[1],pd._libs.tslibs.nattype.NaTType)):\n",
    "            new_feature.append(_current[1])\n",
    "        else:\n",
    "            if (_current[2] is None) or (isinstance(_current[2],pd._libs.tslibs.nattype.NaTType)):\n",
    "                new_feature.append(_next[1]) # Add the next HORAINICIO value\n",
    "            else:\n",
    "                new_feature.append(_current[2]) # Add the current HORAFINAL value\n",
    "    else:\n",
    "        new_feature.append(_current[2]) # Add the current HORAFINAL value\n",
    "\n",
    "new_feature.append(_current[2]) # Add the current HORAFINAL value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations['HORAFINAL'] = new_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fulfill Missing <b>CRONOMETROFINAL</b> Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def get_next(some_iterable, window=1):\n",
    "    items, nexts = itertools.tee(some_iterable, 2)\n",
    "    nexts = itertools.islice(nexts, window, None)\n",
    "    return zip(items, nexts)\n",
    "\n",
    "new_feature = []\n",
    "\n",
    "for _current, _next in get_next(zip(annotations['PARTICIPANTE'], annotations['CRONOMETROINICIO'],annotations['CRONOMETROFINAL'])):\n",
    "    if _next[0] == _current[0]:\n",
    "        if (_current[1] is None) or (isinstance(_current[1],pd._libs.tslibs.nattype.NaTType)):\n",
    "            new_feature.append(_current[1])\n",
    "        else:\n",
    "            if (_current[2] is None) or (isinstance(_current[2],pd._libs.tslibs.nattype.NaTType)):\n",
    "                new_feature.append(_next[1]) # Add the next HORAINICIO value\n",
    "            else:\n",
    "                new_feature.append(_current[2]) # Add the current HORAFINAL value\n",
    "    else:\n",
    "        new_feature.append(_current[2]) # Add the current HORAFINAL value\n",
    "\n",
    "new_feature.append(_current[2]) # Add the current HORAFINAL value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations['CRONOMETROFINAL'] = new_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a New Feature from the <b>start time difference</b> and <b>end time difference</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature = []\n",
    "for start, end in zip(annotations['HORAINICIO'],annotations['HORAFINAL']):   \n",
    "    if start is None or isinstance(start,pd._libs.tslibs.nattype.NaTType) or end is None or isinstance(end,pd._libs.tslibs.nattype.NaTType):\n",
    "        new_feature.append(None)\n",
    "    else:\n",
    "        start = start.time()\n",
    "        end = end.time()\n",
    "        new_feature.append(datetime.datetime.combine(datetime.date.today(), end) - datetime.datetime.combine(datetime.date.today(), start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations['HORADIFERENCA'] = new_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a New Feature from the <b>start timer difference</b> and <b>end timer difference</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature = []\n",
    "for start, end in zip(annotations['CRONOMETROINICIO'],annotations['CRONOMETROFINAL']):\n",
    "    if start is None or isinstance(start,pd._libs.tslibs.nattype.NaTType) or end is None or isinstance(end,pd._libs.tslibs.nattype.NaTType):\n",
    "        new_feature.append(None)\n",
    "    else:\n",
    "        new_feature.append(datetime.datetime.combine(datetime.date.today(), end) - datetime.datetime.combine(datetime.date.today(), start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations['CRONOMETRODIFERENCA'] = new_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cast the Timestamp type to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations['HORAINICIO'] = annotations['HORAINICIO'].apply(lambda x: x.to_pydatetime())\n",
    "annotations['HORAFINAL'] = annotations['HORAFINAL'].apply(lambda x: x.to_pydatetime())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unify the many Annotations into Specified Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "unifyAnnotation = {\n",
    "    'baseline':[\n",
    "        'Linha de base sensores (5min)',\n",
    "        'Linha de base sensores'\n",
    "    ],\n",
    "    \n",
    "    'tsst':[\n",
    "        'Fala livre participante',\n",
    "        'Instruções fala livre'\n",
    "    ],\n",
    "    \n",
    "    'arithmetic':[\n",
    "        'Instruções aritmética',\n",
    "        'Tarefa de aritmética'\n",
    "    ],\n",
    "    \n",
    "    'post_test_sensors_1':[\n",
    "        'Pós-teste sensores 1'\n",
    "    ],\n",
    "    \n",
    "    'post_test_sensors_2':[\n",
    "        'Pós-teste sensores 2'\n",
    "        \n",
    "    ],\n",
    "    \n",
    "    'no_category':[\n",
    "        'None',\n",
    "        'Ligou Polar',\n",
    "        'Ligou Esense',\n",
    "        'Ligou Bewell',\n",
    "        'Ligou Bewell 1 – mão',\n",
    "        'Ligou Bewell 2 – peito',\n",
    "        'Instruções para coleta da linha de base',\n",
    "        'Pré-teste instrumentos',\n",
    "        'Trajeto sala TSST',\n",
    "        'Instruções para o participante',\n",
    "        'Saída da sala pesquisadora',\n",
    "        'Trajeto sala Pós-teste',\n",
    "        'Saída da sala participante',\n",
    "        'Pós-teste Instrumentos',\n",
    "        'Trajeto sala Pós-teste',\n",
    "        'Coleta Saliva',\n",
    "        'Coleta Saliva I (-1min)',\n",
    "        'Coleta Saliva II (+1min)',\n",
    "        'Coleta Saliva III',\n",
    "        'Coleta Saliva IV (+30min)',\n",
    "        'Final – participante liberado',\n",
    "        'Final - participante liberado',\n",
    "        'Fim desligar sensores',\n",
    "        'Fim - desligar sensores',\n",
    "        'Preparação participante',\n",
    "        'Fim – desligar sensores'\n",
    "    ]\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeConfusingAnnotations(x):\n",
    "    if x is None:\n",
    "        return x\n",
    "    \n",
    "    x = x.lower().rstrip().lstrip()\n",
    "    for k in unifyAnnotation.keys():\n",
    "        if (k.lower() in x) or (x in k.lower()):\n",
    "            return k\n",
    "        else:\n",
    "            for y in unifyAnnotation[k]:\n",
    "                #print('{0} -> {1} : {2}'.format(x, y.lower(), (y.lower() in x) or (x in y.lower())))\n",
    "                if (y.lower() in x) or (x in y.lower()):\n",
    "                    return k\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations['CATEGORIACOMPARACAO'] = annotations['CATEGORIA'].apply(lambda x: mergeConfusingAnnotations(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = annotations[['CATEGORIA','CATEGORIACOMPARACAO']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations['CATEGORIA'] = annotations['CATEGORIA'].apply(lambda x: mergeConfusingAnnotations(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Relates the Data and Annotations</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relates the Annotation <b>category</b> with Data by <b>participant</b>, <b>start time</b>, and <b>end time</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['CATEGORY'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "_categories = {}\n",
    "\n",
    "for pat in annotations['PARTICIPANTE'].unique():\n",
    "    _participant = {}\n",
    "    for cat in annotations['CATEGORIA'].unique():      \n",
    "        condition = ((annotations['PARTICIPANTE'] == pat) & (annotations['CATEGORIA'] == cat))\n",
    "        pat_min = annotations[condition]['HORAINICIO'].min()\n",
    "        pat_max = annotations[condition]['HORAFINAL'].max()\n",
    "\n",
    "        _participant[cat] = (pat_min,pat_max)\n",
    "        \n",
    "    _categories[pat] = _participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index = list(range(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TIMESTAMP'] = data['TIMESTAMP'].apply(lambda x: x.tz_localize(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature = {}\n",
    "for x in zip(data.index, data['PARTICIPANT'], data['TIMESTAMP']):\n",
    "    if x[1] in _categories.keys():\n",
    "        for cat in _categories[x[1]]:\n",
    "            pat_min = _categories[x[1]][cat][0]\n",
    "            pat_max = _categories[x[1]][cat][1]\n",
    "\n",
    "            if (x[2] >= pat_min) & (x[2] <= pat_max):\n",
    "                new_feature[x[0]] =  cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature = [new_feature[x] if x in new_feature else None for x in data.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['CATEGORY'] = new_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete unused columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(['TIMESTAMP','PARTICIPANT'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the <b>\"no_category\"</b> data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data.loc[data['CATEGORY'] != \"no_category\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Method to Create the File for Each Category</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_category (new_data, write_data, category):\n",
    "    new_df = pd.DataFrame(columns = ['ECG', 'EMG', 'EDA', 'CATEGORY'])\n",
    "    df = new_data.loc[new_data['CATEGORY'] == category].copy()\n",
    "    \n",
    "    sampling_rate_reducer = 1000\n",
    "    size = (len(df)-(sampling_rate_reducer*2))\n",
    "    \n",
    "    x = 0\n",
    "    position = 0\n",
    "    while (position < size) :\n",
    "        new_df = new_df.append(df[position:position+sampling_rate_reducer])\n",
    "        position = position+sampling_rate_reducer\n",
    "        auxiliary = df[position:position+sampling_rate_reducer] \n",
    "        delta_ecg = auxiliary['ECG'].mean()\n",
    "        delta_emg = auxiliary['EMG'].mean()\n",
    "        delta_eda = auxiliary['EDA'].mean()\n",
    "        delta_category = category\n",
    "        position = position+sampling_rate_reducer\n",
    "        delta = pd.DataFrame({'ECG' : [delta_ecg],'EMG' : [delta_emg],'EDA' : [delta_eda],'CATEGORY' : [delta_category]})\n",
    "        new_df = new_df.append(delta)\n",
    "    \n",
    "    new_df.to_csv(write_data, index=None, header=True, sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create File for <b>\"baseline\"</b> Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'baseline'\n",
    "file = write_data + category + file_type\n",
    "create_category (new_data, file, category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create File for <b>\"tsst\"</b> Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'tsst'\n",
    "file = write_data + category + file_type\n",
    "create_category (new_data, file, category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create File for <b>\"arithmetic\"</b> Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'arithmetic'\n",
    "file = write_data + category + file_type\n",
    "create_category (new_data, file, category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create File for <b>\"post_test_sensores_1\"</b> Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'post_test_sensors_1'\n",
    "file = write_data + category + file_type\n",
    "create_category (new_data, file, category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create File for <b>\"post_test_sensores_2\"</b> Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'post_test_sensors_2'\n",
    "file = write_data + category + file_type\n",
    "create_category (new_data, file, category)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
