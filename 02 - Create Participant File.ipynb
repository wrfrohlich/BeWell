{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\" face=\"Times\"> <b>Create Participant File</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Variables</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant = \"P091\"\n",
    "read_raw_data = \"D:/Unisinos/Bitalino/01 - Raw Data/\" + participant + \"/\"\n",
    "read_annotations = \"D:/Unisinos/Bitalino/02 - Data Control/annotations.csv\"\n",
    "write_data = \"D:/Unisinos/Bitalino/05 - Data CSV for ML/Participants/\" + participant + \"_File.csv\"\n",
    "reading_folder = \"D:/Unisinos/Bitalino/03 - Data CSV/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Libraries</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pytz\n",
    "import datetime\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from collections import Counter\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Read All the Files and Process the Data </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_pwd = read_raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201806130369 - 1568307210\n",
      "201806130369 - 1568308186\n",
      "201806130369 - 1568309371\n",
      "201806130369 - 1568310201\n"
     ]
    }
   ],
   "source": [
    "files = {}\n",
    "data = []\n",
    "for participant_folder in listdir(_pwd):\n",
    "    _participant = participant_folder.split(' ')[1]\n",
    "    for folder in listdir(_pwd + participant_folder):\n",
    "        print(folder)\n",
    "        data_timestamp = int(folder.split('-')[1].lstrip())\n",
    "        data_timestamp = datetime.datetime.fromtimestamp(data_timestamp)\n",
    "\n",
    "        files = [f for f in listdir(_pwd+participant_folder+'/'+folder) if isfile(join(_pwd+participant_folder+'/'+folder, f))]\n",
    "\n",
    "        for f in files:\n",
    "            file_index = int(f.split('.')[0])\n",
    "            data_values = pickle.load(open(_pwd+participant_folder+'/'+folder+'/'+f, \"rb\")).tolist()\n",
    "            data_values = pd.DataFrame(data_values)\n",
    "            data_values.columns = ['DIGITAL{0}'.format(x) for x in range(0,len(data_values.columns))]\n",
    "            data_values.rename(columns={'DIGITAL6':'ECG','DIGITAL7':'EMG','DIGITAL8':'EDA'}, inplace=True)\n",
    "            data_values['PARTICIPANT'] = _participant\n",
    "\n",
    "            data_values['ECG'] = [((((x/1024)-(1/2))*3.3)/1100)*1000 for x in data_values['ECG']]\n",
    "\n",
    "            data_values['FILEINDEX'] = file_index\n",
    "\n",
    "            # At each entry counts as a more one milesecond (@1000Hz)\n",
    "            row_objects = [1000]*len(data_values)\n",
    "            row_objects = list(np.cumsum(row_objects))\n",
    "            row_objects = [data_timestamp + datetime.timedelta(milliseconds=int(x)) for x in row_objects]\n",
    "\n",
    "            data.append(pd.concat([pd.DataFrame(row_objects, columns=['TIMESTAMP']), data_values], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Merge All Data into a Same Data Frame </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the TIMESTAMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TIMESTAMP'] = data['TIMESTAMP'].apply(lambda x: x.to_pydatetime().replace(tzinfo=pytz.timezone('America/Sao_Paulo')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values(['TIMESTAMP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete unused columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(['DIGITAL0','DIGITAL1','DIGITAL2','DIGITAL3','DIGITAL4','DIGITAL5','DIGITAL9','DIGITAL10','FILEINDEX'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Read the Annotations and Preprocess<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = pd.read_csv(read_annotations, sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace NaN with None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = annotations.where((pd.notnull(annotations)), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations['PARTICIPANTE'] = annotations['PARTICIPANTE'].apply(lambda x: x.lstrip().rstrip() if x is not None else x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List Unique Participants of Datas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method to Combine <b>Date</b> and <b>Time</b> into a <b>Datetime</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_date_time(xdate, xtime):\n",
    "    new_feature = []\n",
    "    for d,t in zip(xdate,xtime):\n",
    "        if d is None or t is None:\n",
    "            new_feature.append(None)\n",
    "        else:\n",
    "            new_feature.append(datetime.datetime.strptime(d + ' ' + t, '%d/%m/%Y %H:%M'))\n",
    "    return new_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_date_time(xdate, xtime):\n",
    "    new_feature = []\n",
    "    for d,t in zip(xdate,xtime):\n",
    "        if d is None or t is None:\n",
    "            new_feature.append(None)\n",
    "        else:\n",
    "            new_feature.append(datetime.datetime.strptime(t, '%d-%m-%Y %H:%M'))\n",
    "    return new_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cast <b>Start Time</b> and <b>End Time</b> into <b>Datetime</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations['HORAINICIO'] = combine_date_time(annotations['DATA'],annotations['HORAINICIO'])\n",
    "annotations['HORAFINAL'] = combine_date_time(annotations['DATA'],annotations['HORAFINAL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cast <b>timer</b> into <b>datetime.time</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations['CRONOMETROINICIO'] = annotations['CRONOMETROINICIO'].apply(lambda x: datetime.datetime.strptime(x, '%H:%M:%S').time() if isinstance(x, str) else None)\n",
    "annotations['CRONOMETROFINAL'] = annotations['CRONOMETROFINAL'].apply(lambda x: datetime.datetime.strptime(x, '%H:%M:%S').time() if isinstance(x, str) else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fulfill Missing <b>HORAFINAL</b> Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def get_next(some_iterable, window=1):\n",
    "    items, nexts = itertools.tee(some_iterable, 2)\n",
    "    nexts = itertools.islice(nexts, window, None)\n",
    "    return zip(items, nexts)\n",
    "\n",
    "new_feature = []\n",
    "\n",
    "for _current, _next in get_next(zip(annotations['PARTICIPANTE'], annotations['HORAINICIO'],annotations['HORAFINAL'])):\n",
    "    if _next[0] == _current[0]:\n",
    "        if (_current[1] is None) or (isinstance(_current[1],pd._libs.tslibs.nattype.NaTType)):\n",
    "            new_feature.append(_current[1])\n",
    "        else:\n",
    "            if (_current[2] is None) or (isinstance(_current[2],pd._libs.tslibs.nattype.NaTType)):\n",
    "                new_feature.append(_next[1]) # Add the next HORAINICIO value\n",
    "            else:\n",
    "                new_feature.append(_current[2]) # Add the current HORAFINAL value\n",
    "    else:\n",
    "        new_feature.append(_current[2]) # Add the current HORAFINAL value\n",
    "\n",
    "new_feature.append(_current[2]) # Add the current HORAFINAL value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations['HORAFINAL'] = new_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fulfill Missing <b>CRONOMETROFINAL</b> Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def get_next(some_iterable, window=1):\n",
    "    items, nexts = itertools.tee(some_iterable, 2)\n",
    "    nexts = itertools.islice(nexts, window, None)\n",
    "    return zip(items, nexts)\n",
    "\n",
    "new_feature = []\n",
    "\n",
    "for _current, _next in get_next(zip(annotations['PARTICIPANTE'], annotations['CRONOMETROINICIO'],annotations['CRONOMETROFINAL'])):\n",
    "    if _next[0] == _current[0]:\n",
    "        if (_current[1] is None) or (isinstance(_current[1],pd._libs.tslibs.nattype.NaTType)):\n",
    "            new_feature.append(_current[1])\n",
    "        else:\n",
    "            if (_current[2] is None) or (isinstance(_current[2],pd._libs.tslibs.nattype.NaTType)):\n",
    "                new_feature.append(_next[1]) # Add the next HORAINICIO value\n",
    "            else:\n",
    "                new_feature.append(_current[2]) # Add the current HORAFINAL value\n",
    "    else:\n",
    "        new_feature.append(_current[2]) # Add the current HORAFINAL value\n",
    "\n",
    "new_feature.append(_current[2]) # Add the current HORAFINAL value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations['CRONOMETROFINAL'] = new_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a New Feature from the <b>start time difference</b> and <b>end time difference</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature = []\n",
    "for start, end in zip(annotations['HORAINICIO'],annotations['HORAFINAL']):   \n",
    "    if start is None or isinstance(start,pd._libs.tslibs.nattype.NaTType) or end is None or isinstance(end,pd._libs.tslibs.nattype.NaTType):\n",
    "        new_feature.append(None)\n",
    "    else:\n",
    "        start = start.time()\n",
    "        end = end.time()\n",
    "        new_feature.append(datetime.datetime.combine(datetime.date.today(), end) - datetime.datetime.combine(datetime.date.today(), start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations['HORADIFERENCA'] = new_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a New Feature from the <b>start timer difference</b> and <b>end timer difference</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature = []\n",
    "for start, end in zip(annotations['CRONOMETROINICIO'],annotations['CRONOMETROFINAL']):\n",
    "    if start is None or isinstance(start,pd._libs.tslibs.nattype.NaTType) or end is None or isinstance(end,pd._libs.tslibs.nattype.NaTType):\n",
    "        new_feature.append(None)\n",
    "    else:\n",
    "        new_feature.append(datetime.datetime.combine(datetime.date.today(), end) - datetime.datetime.combine(datetime.date.today(), start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations['CRONOMETRODIFERENCA'] = new_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cast the Timestamp type to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations['HORAINICIO'] = annotations['HORAINICIO'].apply(lambda x: x.to_pydatetime())\n",
    "annotations['HORAFINAL'] = annotations['HORAFINAL'].apply(lambda x: x.to_pydatetime())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unify the many Annotations into Specified Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "unifyAnnotation = {\n",
    "    'baseline':[\n",
    "        'Linha de base sensores (5min)',\n",
    "        'Linha de base sensores'\n",
    "    ],\n",
    "    \n",
    "    'tsst':[\n",
    "        'Fala livre participante',\n",
    "        'Instruções fala livre'\n",
    "    ],\n",
    "    \n",
    "    'arithmetic':[\n",
    "        'Instruções aritmética',\n",
    "        'Tarefa de aritmética'\n",
    "    ],\n",
    "    \n",
    "    'post_test_sensors_1':[\n",
    "        'Pós-teste sensores 1'\n",
    "    ],\n",
    "    \n",
    "    'post_test_sensors_2':[\n",
    "        'Pós-teste sensores 2'\n",
    "        \n",
    "    ],\n",
    "    \n",
    "    'no_category':[\n",
    "        'None',\n",
    "        'Ligou Polar',\n",
    "        'Ligou Esense',\n",
    "        'Ligou Bewell',\n",
    "        'Ligou Bewell 1 – mão',\n",
    "        'Ligou Bewell 2 – peito',\n",
    "        'Instruções para coleta da linha de base',\n",
    "        'Pré-teste instrumentos',\n",
    "        'Trajeto sala TSST',\n",
    "        'Instruções para o participante',\n",
    "        'Saída da sala pesquisadora',\n",
    "        'Trajeto sala Pós-teste',\n",
    "        'Saída da sala participante',\n",
    "        'Pós-teste Instrumentos',\n",
    "        'Trajeto sala Pós-teste',\n",
    "        'Coleta Saliva',\n",
    "        'Coleta Saliva I (-1min)',\n",
    "        'Coleta Saliva II (+1min)',\n",
    "        'Coleta Saliva III',\n",
    "        'Coleta Saliva IV (+30min)',\n",
    "        'Final – participante liberado',\n",
    "        'Final - participante liberado',\n",
    "        'Fim desligar sensores',\n",
    "        'Fim - desligar sensores',\n",
    "        'Preparação participante',\n",
    "        'Fim – desligar sensores'\n",
    "    ]\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeConfusingAnnotations(x):\n",
    "    if x is None:\n",
    "        return x\n",
    "    \n",
    "    x = x.lower().rstrip().lstrip()\n",
    "    for k in unifyAnnotation.keys():\n",
    "        if (k.lower() in x) or (x in k.lower()):\n",
    "            return k\n",
    "        else:\n",
    "            for y in unifyAnnotation[k]:\n",
    "                #print('{0} -> {1} : {2}'.format(x, y.lower(), (y.lower() in x) or (x in y.lower())))\n",
    "                if (y.lower() in x) or (x in y.lower()):\n",
    "                    return k\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations['CATEGORIACOMPARACAO'] = annotations['CATEGORIA'].apply(lambda x: mergeConfusingAnnotations(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = annotations[['CATEGORIA','CATEGORIACOMPARACAO']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations['CATEGORIA'] = annotations['CATEGORIA'].apply(lambda x: mergeConfusingAnnotations(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Relates the Data and Annotations</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relates the Annotation <b>category</b> with Data by <b>participant</b>, <b>start time</b>, and <b>end time</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['CATEGORY'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "_categories = {}\n",
    "\n",
    "for pat in annotations['PARTICIPANTE'].unique():\n",
    "    _participant = {}\n",
    "    for cat in annotations['CATEGORIA'].unique():      \n",
    "        condition = ((annotations['PARTICIPANTE'] == pat) & (annotations['CATEGORIA'] == cat))\n",
    "        pat_min = annotations[condition]['HORAINICIO'].min()\n",
    "        pat_max = annotations[condition]['HORAFINAL'].max()\n",
    "\n",
    "        _participant[cat] = (pat_min,pat_max)\n",
    "        \n",
    "    _categories[pat] = _participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index = list(range(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TIMESTAMP'] = data['TIMESTAMP'].apply(lambda x: x.tz_localize(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature = {}\n",
    "for x in zip(data.index, data['PARTICIPANT'], data['TIMESTAMP']):\n",
    "    if x[1] in _categories.keys():\n",
    "        for cat in _categories[x[1]]:\n",
    "            pat_min = _categories[x[1]][cat][0]\n",
    "            pat_max = _categories[x[1]][cat][1]\n",
    "\n",
    "            if (x[2] >= pat_min) & (x[2] <= pat_max):\n",
    "                new_feature[x[0]] =  cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature = [new_feature[x] if x in new_feature else None for x in data.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['CATEGORY'] = new_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete unused columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(['TIMESTAMP','PARTICIPANT'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the <b>\"no_category\"</b> data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data.loc[data['CATEGORY'] != \"no_category\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Method to Complement the Data Category - \"baseline\"</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator_baseline(df):\n",
    "    file = \"baseline_file.csv\"\n",
    "    new_df = pd.read_csv(reading_folder + file, sep=';', encoding='utf-8')\n",
    "    df = df.append(new_df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Method to Complement the Data Category - \"tsst\"</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator_tsst(df):\n",
    "    file = \"tsst_file.csv\"\n",
    "    new_df = pd.read_csv(reading_folder + file, sep=';', encoding='utf-8')\n",
    "    df = df.append(new_df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Method to Complement the Data Category - \"arithmetic\"</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator_arithmetic(df):\n",
    "    file = \"arithmetic_file.csv\"\n",
    "    new_df = pd.read_csv(reading_folder + file, sep=';', encoding='utf-8')\n",
    "    df = df.append(new_df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Method to Complement the Data Category - \"post_test_sensors_1\"</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator_post_test_sensors_1(df):\n",
    "    file = \"post_test_sensors_1_file.csv\"\n",
    "    new_df = pd.read_csv(reading_folder + file, sep=';', encoding='utf-8')\n",
    "    df = df.append(new_df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Method to Complement the Data Category - \"post_test_sensors_2\"</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator_post_test_sensors_2(df):\n",
    "    file = \"post_test_sensors_2_file.csv\"\n",
    "    new_df = pd.read_csv(reading_folder + file, sep=';', encoding='utf-8')\n",
    "    df = df.append(new_df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Method to Compare the Size Each Category</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparator (new_data):\n",
    "    size_baseline = len(new_data.loc[new_data[\"CATEGORY\"]==\"baseline\"])\n",
    "    size_tsst = len(new_data.loc[new_data[\"CATEGORY\"]==\"tsst\"])\n",
    "    size_arithmetic = len(new_data.loc[new_data[\"CATEGORY\"]==\"arithmetic\"])\n",
    "    size_post_test_sensors_1 = len(new_data.loc[new_data[\"CATEGORY\"]==\"post_test_sensors_1\"])\n",
    "    size_post_test_sensors_2 = len(new_data.loc[new_data[\"CATEGORY\"]==\"post_test_sensors_2\"])\n",
    "    \n",
    "    print(\"Baseline: \" + str(size_baseline))\n",
    "    print(\"TSST: \" + str(size_tsst))\n",
    "    print(\"Arithmetic: \" + str(size_arithmetic))\n",
    "    print(\"Post Test Sensors I: \" + str(size_post_test_sensors_1))\n",
    "    print(\"Post Test Sensors II: \" + str(size_post_test_sensors_2))\n",
    "    \n",
    "        \n",
    "    if (size_baseline <= 25000):\n",
    "        size_baseline = 100000000\n",
    "    \n",
    "    if (size_tsst <= 25000):\n",
    "        size_tsst = 100000000\n",
    "        \n",
    "    if (size_arithmetic <= 25000):\n",
    "        size_arithmetic = 100000000\n",
    "        \n",
    "    if (size_post_test_sensors_1 <= 25000):\n",
    "        size_post_test_sensors_1 = 100000000\n",
    "        \n",
    "    if (size_post_test_sensors_2 <= 25000):\n",
    "        size_post_test_sensors_2 = 100000000\n",
    "    \n",
    "    if (size_baseline <= size_tsst):\n",
    "        if (size_baseline <= size_arithmetic):\n",
    "            if (size_baseline <= size_post_test_sensors_1):\n",
    "                if (size_baseline <= size_post_test_sensors_2):\n",
    "                    smaller = size_baseline\n",
    "                else:\n",
    "                    smaller = size_post_test_sensors_2\n",
    "            else:\n",
    "                if (size_post_test_sensors_1 <= size_post_test_sensors_2):\n",
    "                    smaller = size_post_test_sensors_1\n",
    "                else:\n",
    "                    smaller = size_post_test_sensors_2\n",
    "        else:\n",
    "            if (size_arithmetic <= size_post_test_sensors_1):\n",
    "                if (size_arithmetic <= size_post_test_sensors_2):\n",
    "                    smaller = size_arithmetic\n",
    "                else:\n",
    "                    smaller = size_post_test_sensors_2\n",
    "        \n",
    "            else:\n",
    "                if (size_post_test_sensors_1 <= size_post_test_sensors_2):\n",
    "                    smaller = size_post_test_sensors_1\n",
    "                else:\n",
    "                    smaller = size_post_test_sensors_2\n",
    "            \n",
    "    else:\n",
    "        if (size_tsst <= size_arithmetic):\n",
    "            if (size_tsst <= size_post_test_sensors_1):\n",
    "                if (size_tsst <= size_post_test_sensors_2):\n",
    "                    smaller = size_tsst\n",
    "                    \n",
    "            else:        \n",
    "                if (size_post_test_sensors_1 <= size_post_test_sensors_2):\n",
    "                    smaller = size_post_test_sensors_1\n",
    "                else:\n",
    "                    smaller = size_post_test_sensors_2\n",
    "        else:\n",
    "            if (size_arithmetic <= size_post_test_sensors_1):\n",
    "                if (size_arithmetic <= size_post_test_sensors_2):\n",
    "                    smaller = size_arithmetic\n",
    "                else:\n",
    "                    smaller = size_post_test_sensors_2\n",
    "        \n",
    "            else:\n",
    "                if (size_post_test_sensors_1 <= size_post_test_sensors_2):\n",
    "                    smaller = size_post_test_sensors_1\n",
    "                else:\n",
    "                    smaller = size_post_test_sensors_2\n",
    "    print (smaller)\n",
    "                    \n",
    "    return smaller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Method to Create File for Each Category</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(new_data, minimum_size):\n",
    "    size_baseline = len(new_data.loc[new_data[\"CATEGORY\"]==\"baseline\"])\n",
    "    size_tsst = len(new_data.loc[new_data[\"CATEGORY\"]==\"tsst\"])\n",
    "    size_arithmetic = len(new_data.loc[new_data[\"CATEGORY\"]==\"arithmetic\"])\n",
    "    size_post_test_sensors_1 = len(new_data.loc[new_data[\"CATEGORY\"]==\"post_test_sensors_1\"])\n",
    "    size_post_test_sensors_2 = len(new_data.loc[new_data[\"CATEGORY\"]==\"post_test_sensors_2\"])\n",
    "    \n",
    "    if (size_baseline <= 25000):\n",
    "        data_baseline = new_data.loc[new_data['CATEGORY'] == \"baseline\"].copy()\n",
    "        data_baseline = data_generator_baseline(data_baseline)\n",
    "        data_save = (data_baseline[0:minimum_size])\n",
    "    else:\n",
    "        data_baseline = new_data.loc[new_data['CATEGORY'] == \"baseline\"].copy()\n",
    "        data_save = (data_baseline[0:minimum_size])\n",
    "    \n",
    "    if (size_tsst <= 25000):\n",
    "        data_tsst = new_data.loc[new_data['CATEGORY'] == \"tsst\"].copy()\n",
    "        data_tsst = data_generator_tsst(data_tsst)\n",
    "        data_save = data_save.append(data_tsst[0:minimum_size])\n",
    "    else:\n",
    "        data_tsst = new_data.loc[new_data['CATEGORY'] == \"tsst\"].copy()\n",
    "        data_save = data_save.append(data_tsst[0:minimum_size])\n",
    "    \n",
    "    if (size_arithmetic <= 25000):\n",
    "        data_arithmetic = new_data.loc[new_data['CATEGORY'] == \"arithmetic\"].copy()\n",
    "        data_arithmetic = data_generator_arithmetic(data_arithmetic)\n",
    "        data_save = data_save.append(data_arithmetic[0:minimum_size])\n",
    "    else:\n",
    "        data_arithmetic = new_data.loc[new_data['CATEGORY'] == \"arithmetic\"].copy()\n",
    "        data_save = data_save.append(data_arithmetic[0:minimum_size])\n",
    "        \n",
    "    if (size_post_test_sensors_1 <= 25000):\n",
    "        data_post_test_sensors_1 = new_data.loc[new_data['CATEGORY'] == \"post_test_sensors_1\"].copy()\n",
    "        data_post_test_sensors_1 = data_generator_post_test_sensors_1(data_post_test_sensors_1)\n",
    "        data_save = data_save.append(data_post_test_sensors_1[0:minimum_size])\n",
    "    else:\n",
    "        data_post_test_sensors_1 = new_data.loc[new_data['CATEGORY'] == \"post_test_sensors_1\"].copy()\n",
    "        data_save = data_save.append(data_post_test_sensors_1[0:minimum_size])\n",
    "        \n",
    "    if (size_post_test_sensors_2 <= 25000):\n",
    "        data_post_test_sensors_2 = new_data.loc[new_data['CATEGORY'] == \"post_test_sensors_2\"].copy()\n",
    "        data_post_test_sensors_2 = data_generator_post_test_sensors_2(data_post_test_sensors_2)\n",
    "        data_save = data_save.append(data_post_test_sensors_2[0:minimum_size])\n",
    "    else:\n",
    "        data_post_test_sensors_2 = new_data.loc[new_data['CATEGORY'] == \"post_test_sensors_2\"].copy()\n",
    "        data_save = data_save.append(data_post_test_sensors_2[0:minimum_size])\n",
    "        \n",
    "    return data_save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the <b>\"comparator\"</b> Method to Find the Smaller Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 139230\n",
      "TSST: 73931\n",
      "Arithmetic: 346907\n",
      "Post Test Sensors I: 584527\n",
      "Post Test Sensors II: 741600\n",
      "73931\n"
     ]
    }
   ],
   "source": [
    "minimum_size = comparator(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the <b> \"data_generator\" </b> Method to Generate the File with Standardized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_save = data_generator(new_data, minimum_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the <b>\"comparator\"</b> Verify the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 73931\n",
      "TSST: 73931\n",
      "Arithmetic: 73931\n",
      "Post Test Sensors I: 73931\n",
      "Post Test Sensors II: 73931\n",
      "73931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "73931"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparator(data_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the standardized file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_save.to_csv(write_data, index=None, header=True, sep=';', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
